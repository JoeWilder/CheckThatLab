{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheckThat Task 2\n",
    "\n",
    "The goal here is to find a method to extract a claim from a passage of text. For example:\n",
    "\n",
    "\n",
    "- **Passage**: Hydrate YOURSELF W After Waking Up Water 30 min Before a Meal DRINK Before Taking a Shower →→ Before Going to Bed at the correct time T A YE Helps activate internal organs Helps digestion Helps lower blood pressure Helps to avoid heart attack Health+ by Punjab Kesari\n",
    "\n",
    "- **Claim**: Drinking water at specific times can have different health benefits\n",
    "\n",
    "\n",
    "To evaluate our method, we will use the **METEOR** metric on the **CLEF2025** dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download(url, path=None):\n",
    "    get_response = requests.get(url,stream=True)\n",
    "    filename  = url.split(\"/\")[-1].split(\"?\")[0]\n",
    "\n",
    "\n",
    "    if path is not None:\n",
    "        filename = os.path.join(path, filename)\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        for chunk in get_response.iter_content(chunk_size=1024):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METEOR Metric Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jwilder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0566\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate import meteor\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def evaluate_claim_extraction(text_passage: str, claim: str, precision: int = 4):\n",
    "    return round(meteor([word_tokenize(text_passage)], word_tokenize(claim)), precision)\n",
    "\n",
    "text_passage = \"Hydrate YOURSELF W After Waking Up Water 30 min Before a Meal DRINK Before Taking a Shower →→ Before Going to Bed at the correct time T A YE Helps activate internal organs Helps digestion Helps lower blood pressure Helps to avoid heart attack Health+ by Punjab Kesari\"\n",
    "claim = \"Drinking water at specific times can have different health benefits\"\n",
    "score = evaluate_claim_extraction(text_passage, claim)\n",
    "print(score)\n",
    "\n",
    "text_passage = \"I enjoy eating soup\"\n",
    "claim = \"I consume soup sometimes\"\n",
    "score = evaluate_claim_extraction(text_passage, claim)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_url = \"https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task2/data/train/train-eng.csv?inline=false\"\n",
    "test_url = \"https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task2/data/dev/dev-eng.csv?inline=false\"\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "download(train_url, \"data\")\n",
    "download(test_url, \"data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Tuple\n",
    "\n",
    "class ClaimVerificationDataset(Dataset):\n",
    "    def __init__(self, csv_path: str):\n",
    "        self.csv_path = csv_path\n",
    "        self.data = self.parse_csv(self.csv_path)\n",
    "\n",
    "    def parse_csv(self, csv_path: str) -> List[Tuple[str, str]]:\n",
    "        csv_data = []\n",
    "        try:\n",
    "            with open(csv_path, 'r', encoding=\"utf8\") as file:\n",
    "                csv_reader = csv.reader(file)\n",
    "                next(csv_reader) # skip header\n",
    "                \n",
    "                for row in csv_reader:\n",
    "                    csv_data.append({\"text\": row[0], \"claim\": row[1]})\n",
    "            return csv_data\n",
    "                    \n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at '{csv_path}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[str, str]:\n",
    "        return self.data[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ClaimVerificationDataset(f\"data/train-eng.csv\")\n",
    "test_dataset = ClaimVerificationDataset(f\"data/dev-eng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 11374\n",
      "Test dataset length: 1171\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset length: {len(train_dataset)}\")\n",
    "print(f\"Test dataset length: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "\n",
    "First we will try some basic prompt engineering to see if we can condition a LLM to extract claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from together import Together\n",
    "\n",
    "def ask_llm(client: Together,\n",
    "            model: str = \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"How are you?\"}]):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drinking water at specific times (after waking up, 30 minutes before a meal, before taking a shower, and before going to bed) helps to: \n",
      "1. Activate internal organs\n",
      "2. Aid digestion\n",
      "3. Lower blood pressure\n",
      "4. Avoid heart attack.\n"
     ]
    }
   ],
   "source": [
    "client = Together()\n",
    "prompt = \"Take a look at the following article. It is your job to look at it and extract what is being claimed. Return to the user only the claim: Hydrate YOURSELF W After Waking Up Water 30 min Before a Meal DRINK Before Taking a Shower →→ Before Going to Bed at the correct time T A YE Helps activate internal organs Helps digestion Helps lower blood pressure Helps to avoid heart attack Health+ by Punjab Kesari\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "output = ask_llm(client, messages=messages)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are an AI assistant designed to extract claims from a given passage of text. Keep it short and return the claim in the text.'}, {'role': 'user', 'content': 'Lieutenant Retired General Asif Mumtaz appointed as Chairman Pakistan Medical Commission PMC Lieutenant Retired General Asif Mumtaz appointed as Chairman Pakistan Medical Commission PMC Lieutenant Retired General Asif Mumtaz appointed as Chairman Pakistan Medical Commission PMC None'}, {'role': 'assistant', 'content': 'Pakistani government appoints former army general to head medical regulatory body'}, {'role': 'user', 'content': 'A priceless clip of 1970 of Bruce Lee playing Table Tennis with his Nan-chak !! His focus on speed A priceless clip of 1970 of Bruce Lee playing Table Tennis with his Nan-chak !! His focus on speed A priceless clip of 1970 of Bruce Lee playing Table Tennis with his Nan-chak !! His focus on speed None'}, {'role': 'assistant', 'content': 'Late actor and martial artist Bruce Lee playing table tennis with a set of nunchucks.'}, {'role': 'user', 'content': 'Hydrate\\nYOURSELF\\nW\\nAfter Waking Up\\nWater\\n30 min Before a Meal\\nDRINK\\nBefore Taking a Shower →→\\nBefore Going to Bed\\nat the correct time\\nT\\nA\\nYE\\nHelps activate\\ninternal\\norgans\\nHelps\\ndigestion\\nHelps lower\\nblood pressure\\nHelps to avoid\\nheart attack\\nHealth+\\nby Punjab Kesari'}, {'role': 'assistant', 'content': 'Drinking water at specific times can have different health benefits'}, {'role': 'user', 'content': 'Hydrate YOURSELF W After Waking Up Water 30 min Before a Meal DRINK Before Taking a Shower →→ Before Going to Bed at the correct time T A YE Helps activate internal organs Helps digestion Helps lower blood pressure Helps to avoid heart attack Health+ by Punjab Kesari'}]\n",
      "Drinking water at certain times, such as after waking up and before meals, can help activate internal organs, aid digestion, lower blood pressure, and reduce the risk of heart attack.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hydrate YOURSELF W After Waking Up Water 30 min Before a Meal DRINK Before Taking a Shower →→ Before Going to Bed at the correct time T A YE Helps activate internal organs Helps digestion Helps lower blood pressure Helps to avoid heart attack Health+ by Punjab Kesari\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are an AI assistant designed to extract claims from a given passage of text. Keep it short and return the claim in the text.\"},\n",
    "            {\"role\": \"user\", \"content\": train_dataset[0][\"text\"]},\n",
    "            {\"role\": \"assistant\", \"content\": train_dataset[0][\"claim\"]},\n",
    "            {\"role\": \"user\", \"content\": train_dataset[1][\"text\"]},\n",
    "            {\"role\": \"assistant\", \"content\": train_dataset[1][\"claim\"]},\n",
    "            {\"role\": \"user\", \"content\": train_dataset[2][\"text\"]},\n",
    "            {\"role\": \"assistant\", \"content\": train_dataset[2][\"claim\"]},\n",
    "            {\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "print(messages)\n",
    "\n",
    "output = ask_llm(client, messages=messages)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will run evaluation on the whole test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_llm_method(client: Together, limit: int = None):\n",
    "    data = []\n",
    "    scores = []\n",
    "\n",
    "    counter = 0\n",
    "    for entry in tqdm(test_dataset, desc=\"Evaluating LLM claim extraction\"):\n",
    "        prompt = entry[\"text\"]\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant designed to extract claims from a given passage of text. Keep it short and return the claim in the text. Only return the big idea and exclude unneeded details.\"},\n",
    "            {\"role\": \"user\", \"content\": train_dataset[0][\"text\"]},\n",
    "            {\"role\": \"assistant\", \"content\": train_dataset[0][\"claim\"]},\n",
    "            {\"role\": \"user\", \"content\": train_dataset[1][\"text\"]},\n",
    "            {\"role\": \"assistant\", \"content\": train_dataset[1][\"claim\"]},\n",
    "            {\"role\": \"user\", \"content\": train_dataset[2][\"text\"]},\n",
    "            {\"role\": \"assistant\", \"content\": train_dataset[2][\"claim\"]},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "        output = ask_llm(client, messages=messages)\n",
    "        meteor_score = evaluate_claim_extraction(entry[\"claim\"], output)\n",
    "\n",
    "        data.append({\n",
    "            \"ground_truth_claim\": entry[\"claim\"],\n",
    "            \"generated_claim\": output,\n",
    "            \"meteor_score\": meteor_score\n",
    "        })\n",
    "\n",
    "        scores.append(meteor_score)\n",
    "\n",
    "        counter += 1\n",
    "        if limit and counter >= limit:\n",
    "            break\n",
    "\n",
    "    avg_score = sum(scores) / len(scores) if scores else 0\n",
    "\n",
    "    return data, avg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LLM claim extraction: 100%|██████████| 1171/1171 [2:07:51<00:00,  6.55s/it] \n"
     ]
    }
   ],
   "source": [
    "data, avg_score = evaluate_llm_method(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of our generated claims vs the ground truth claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth claim: Photo shows Louis Armstrong as a child\n",
      "Generated claim: A young Louis Armstrong was taken in by a Jewish family who supported his early musical talent.\n",
      "Score: 0.3155\n",
      "\n",
      "\n",
      "Ground truth claim: This leopard cub's mother was killed by a trophy hunter\n",
      "Generated claim: Trophy hunting is cruel and should be banned.\n",
      "Score: 0.0463\n",
      "\n",
      "\n",
      "Ground truth claim: Videos show current situation of Hyderabad amid heavy rain\n",
      "Generated claim: Crocodile alert issued in Hyderabad due to heavy rain.\n",
      "Score: 0.2808\n",
      "\n",
      "\n",
      "Ground truth claim: Joe Biden lives in a large estate bought on a senator's salary\n",
      "Generated claim: Joe Biden's wealth is questioned given his reported senator salary.\n",
      "Score: 0.3305\n",
      "\n",
      "\n",
      "Ground truth claim: Photo shows August 26, 2021 explosion near Kabul airport\n",
      "Generated claim: Explosion outside Kabul airport kills 40, injures 120, and US administration is being criticized for blaming the victims.\n",
      "Score: 0.2843\n",
      "\n",
      "\n",
      "Ground truth claim: White people own only 22 percent of South Africa’s land\n",
      "Generated claim: White South Africans own 22% of the country's land.\n",
      "Score: 0.25\n",
      "\n",
      "\n",
      "Ground truth claim: This video shows Amitabh Bachchan thanking healthcare workers after he was hospitalised for COVID-19 in July 2020\n",
      "Generated claim: Amitabh Bachchan tests positive for Covid-19.\n",
      "Score: 0.2344\n",
      "\n",
      "\n",
      "Ground truth claim: Publix supermarket chain will stop carrying Ben & Jerry's\n",
      "Generated claim: Publix supermarket stops carrying Ben & Jerry's products due to their stance on Israel.\n",
      "Score: 0.7488\n",
      "\n",
      "\n",
      "Ground truth claim: American Medical Association Rescinds Previous Statement Against Prescription of Hydroxychloroquine to COVID-19 Patients.\n",
      "Generated claim: Hydroxychloroquine was initially dismissed as a fringe idea.\n",
      "Score: 0.0741\n",
      "\n",
      "\n",
      "Ground truth claim: Brazilains participating in India’s nationwide COVID-19 candle light vigil, which Indian Prime Minister Narendra Modi called for on April 3, 2020.\n",
      "Generated claim: Brazilian TV channels aired Indian Prime Minister Modi's speech.\n",
      "Score: 0.182\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    print(f\"Ground truth claim: {data[i][\"ground_truth_claim\"]}\")\n",
    "    print(f\"Generated claim: {data[i][\"generated_claim\"]}\")\n",
    "    print(f\"Score: {data[i][\"meteor_score\"]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2516289496157131\n"
     ]
    }
   ],
   "source": [
    "print(avg_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
